{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM2uzXvD18Z+Ajjhhr800kg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UCoOVTOz0GFr","executionInfo":{"status":"ok","timestamp":1702935010938,"user_tz":-60,"elapsed":239,"user":{"displayName":"Zeno Kujawa","userId":"07762581709440442721"}},"outputId":"5f5c031d-bec9-4a67-a388-85cc7b54bec9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}],"source":["! nvidia-smi -L"]},{"cell_type":"code","source":["!pip install cmake --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"slifDllC0YZC","executionInfo":{"status":"ok","timestamp":1702935128030,"user_tz":-60,"elapsed":8841,"user":{"displayName":"Zeno Kujawa","userId":"07762581709440442721"}},"outputId":"441750ce-66d1-466a-a381-1ef8a1b895ba"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (3.27.9)\n","Collecting cmake\n","  Downloading cmake-3.28.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: cmake\n","  Attempting uninstall: cmake\n","    Found existing installation: cmake 3.27.9\n","    Uninstalling cmake-3.27.9:\n","      Successfully uninstalled cmake-3.27.9\n","Successfully installed cmake-3.28.1\n"]}]},{"cell_type":"code","source":["! wget ftp://ftp.gromacs.org/gromacs/gromacs-2023.3.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GcvOXMou0akQ","executionInfo":{"status":"ok","timestamp":1702935166584,"user_tz":-60,"elapsed":4758,"user":{"displayName":"Zeno Kujawa","userId":"07762581709440442721"}},"outputId":"f5a68ba0-470d-4eb0-95bb-8e1746027336"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-12-18 21:32:41--  ftp://ftp.gromacs.org/gromacs/gromacs-2023.3.tar.gz\n","           => ‘gromacs-2023.3.tar.gz’\n","Resolving ftp.gromacs.org (ftp.gromacs.org)... 130.237.11.165, 2001:6b0:1:1191:216:3eff:fec7:6e30\n","Connecting to ftp.gromacs.org (ftp.gromacs.org)|130.237.11.165|:21... connected.\n","Logging in as anonymous ... Logged in!\n","==> SYST ... done.    ==> PWD ... done.\n","==> TYPE I ... done.  ==> CWD (1) /gromacs ... done.\n","==> SIZE gromacs-2023.3.tar.gz ... 42071770\n","==> PASV ... done.    ==> RETR gromacs-2023.3.tar.gz ... done.\n","Length: 42071770 (40M) (unauthoritative)\n","\n","gromacs-2023.3.tar. 100%[===================>]  40.12M  16.1MB/s    in 2.5s    \n","\n","2023-12-18 21:32:46 (16.1 MB/s) - ‘gromacs-2023.3.tar.gz’ saved [42071770]\n","\n"]}]},{"cell_type":"code","source":["\n","import os\n","\n","if not os.path.isdir(\"/content/drive/MyDrive\"):\n","  from google.colab import drive\n","  drive.mount(\"/content/drive\")\n","\n","if not os.path.isdir(\"/content/drive/MyDrive\"):\n","  raise RuntimeError(\"Error: could not connect to Google Drive\")\n","\n","storage = \"/content/drive/MyDrive/gromacs-on-colab\"\n","os.makedirs(storage, exist_ok=True)\n","%env STORAGE={storage}\n","\n","if \"START\" not in os.environ or not os.environ[\"START\"]:\n","  %env START={os.getcwd()}\n","else:\n","  %cd {os.environ[\"START\"]}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvCjtl_z26lU","executionInfo":{"status":"ok","timestamp":1702938285295,"user_tz":-60,"elapsed":5,"user":{"displayName":"Zeno Kujawa","userId":"07762581709440442721"}},"outputId":"4194cfe4-cdfb-4676-9077-74f62acc32da"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["env: STORAGE=/content/drive/MyDrive/gromacs-on-colab\n","/content\n"]}]},{"cell_type":"code","source":["%%bash\n","# @markdown If not available, it is instead compiled from source code. (This takes a while.)\n","\n","if [[ -d \"/usr/local/gromacs\" ]]; then\n","  exit 0  # already installed\n","fi\n","\n","gromacs_vers=\"2023.3\" #@param {type: \"string\"}\n","cache_gromacs=\"${STORAGE}/gromacs-${gromacs_vers}.tar.gz\"\n","\n","if [[ -s \"${cache_gromacs}\" ]]; then\n","  tar -xzf \"${cache_gromacs}\" -C \"/usr/local\"\n","  # Prebuilt archive not available, so download the source code and build it...\n","else\n","  wget \"https://ftp.gromacs.org/gromacs/gromacs-2023.3.tar.gz\"\n","  if [[ ! -s \"gromacs-${gromacs_vers}.tar.gz\" ]]; then\n","    echo \"Error: could not download: gromacs-${gromacs_vers}.tar.gz\" >&2\n","    exit 1\n","  fi\n","  tar -xzf \"gromacs-${gromacs_vers}.tar.gz\"\n","  rm \"gromacs-${gromacs_vers}.tar.gz\"\n","\n","  cd \"gromacs-${gromacs_vers}\"\n","  mkdir \"build\"\n","  cd \"build\"\n","  cmake .. -DGMX_BUILD_OWN_FFTW=ON -DGMX_GPU=CUDA\n","  make -j $(nproc)\n","  make install # -> /usr/local/gromacs\n","\n","    # Cache\n","  tar -czf \"my_gromacs.tar.gz\" -C \"/usr/local\" \"gromacs\"\n","  mv \"my_gromacs.tar.gz\" \"${cache_gromacs}\"\n","fi"],"metadata":{"id":"rpK_iFvi6cPD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib\n","# Force matplotlib to not use any Xwindows backend.\n","matplotlib.use('Agg')\n","\n","import glob\n","import random\n","import MDAnalysis\n","\n","from scipy.spatial import Voronoi\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from matplotlib.colors import LogNorm\n","from scipy.spatial import cKDTree\n","from tqdm import tqdm\n","\n","\n","def plot_frame_transitions(df, frames, title, lag_time=2, phi_offset=60, psi_offset=-90):\n","    phi_s, phi_e = -180 + phi_offset, 180 + phi_offset\n","    psi_s, psi_e = -180 + psi_offset, 180 + psi_offset\n","\n","    # \"improved\" x/y axis ticks\n","    plt.xticks(np.arange(-180, 180, 30), np.arange(phi_s, phi_e, 30))\n","    plt.yticks(np.arange(-180, 180, 30), np.arange(psi_s, psi_e, 30))\n","\n","    # axis labels (right order?)\n","    plt.xlabel('$\\phi$')\n","    plt.ylabel('$\\psi$')\n","\n","    # 1:1 aspect ratio\n","    plt.axes().set_aspect('equal')\n","    # remove grid lines\n","    plt.axes().grid(False)\n","\n","    if len(title):\n","        plt.title(title)\n","\n","    sd = df.as_matrix()\n","    plt.scatter(sd[0], sd[1], color='red')\n","\n","    for key in tqdm(frames.keys(), desc=\"Plotting transition paths\"):\n","        prev = df.iloc[key]\n","        c = np.random.rand(3,)\n","        for step in range(lag_time):\n","            curr = df.iloc[key + step]\n","            plt.plot([prev[0], curr[0]], [prev[1], curr[1]], color=c, linewidth=1.0)\n","            prev = curr\n","\n","    return plt\n","\n","\n","def plot_groups(df, c_centers, phi_offset=60, psi_offset=-90):\n","    phi_s, phi_e = -180 + phi_offset, 180 + phi_offset\n","    psi_s, psi_e = -180 + psi_offset, 180 + psi_offset\n","\n","    tree = cKDTree(c_centers)\n","    points = np.c_[df['phi'], df['psi']]  # fancy zipping\n","    queries = tree.query(points)[1]\n","    plt.figure()\n","    plt.scatter(df['phi'], df['psi'], c=queries, s=5, linewidths=0.25)\n","\n","    # \"improved\" x/y axis ticks\n","    plt.xlim([-180, 180])\n","    plt.ylim([-180, 180])\n","    # \"improved\" x/y axis ticks\n","    plt.xticks(np.arange(-180, 180, 30), np.arange(phi_s, phi_e, 30))\n","    plt.yticks(np.arange(-180, 180, 30), np.arange(psi_s, psi_e, 30))\n","\n","    # axis labels (right order?)\n","    plt.ylabel('$\\psi$')\n","    plt.xlabel('$\\phi$')\n","\n","    # 1:1 aspect ratio\n","    plt.axes().set_aspect('equal')\n","    # remove grid lines\n","    plt.axes().grid(False)\n","\n","    return plt\n","\n","\n","def create_ramachandran_plot(df, title, colorbar=True, phi_offset=60, psi_offset=-90):\n","    phi_s, phi_e = -180 + phi_offset, 180 + phi_offset\n","    psi_s, psi_e = -180 + psi_offset, 180 + psi_offset\n","\n","    plt.hist2d(df[0], df[1],\n","               range=[[-180, 180], [-180, 180]],  # not really necessary\n","               bins=360,\n","               # cmap='viridis',  # cf. http://matplotlib.org/examples/color/colormaps_reference.html\n","               norm=LogNorm())\n","    if colorbar:\n","        plt.colorbar()\n","\n","    # \"improved\" x/y axis ticks\n","    plt.xticks(np.arange(-180, 180, 30), np.arange(phi_s, phi_e, 30))\n","    plt.yticks(np.arange(-180, 180, 30), np.arange(psi_s, psi_e, 30))\n","\n","    # axis labels (right order?)\n","    plt.xlabel('$\\phi$')\n","    plt.ylabel('$\\psi$')\n","\n","    # 1:1 aspect ratio\n","    plt.axes().set_aspect('equal')\n","    # remove grid lines\n","    plt.axes().grid(False)\n","\n","    if len(title):\n","        plt.title(title)\n","\n","    return plt\n","\n","\n","def plot_voronoi_ridges(ridges, linewidth=1):\n","    for segment in ridges:\n","        plt.plot([segment[0][0], segment[1][0]], [segment[0][1], segment[1][1]], linewidth=linewidth, color='black')\n","\n","\n","def plot_sampled_frames(frames, linewidth=1, n=-1):\n","    sample_frames = pd.DataFrame(frames)\n","    sd = sample_frames.as_matrix()\n","    plt.scatter(sd[0][:n], sd[1][:n], color='red', linewidth=linewidth)\n","import sys\n","\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","\n","def save_frames_as_pdb(frames, u):\n","    # save all frames in pdb files\n","    for idx in tqdm(frames.keys(), desc=\"Saving GRO files for each microstate\"):\n","        u.trajectory[idx]\n","        u.atoms.write('../data/frames/f' + str(idx) + '.gro')\n","\n","\n","def csv_print(mat):\n","    np.savetxt(sys.stdout, mat, fmt='%.5f', newline=\"\\n\")\n","\n","\n","def read_dihedral_angles(phi_path, psi_path, frames=1, phi_offset=60, psi_offset=-90):\n","    phi_df = pd.read_csv(phi_path, header=None,\n","                         index_col='frame', names=['frame', 'phi'],\n","                         delimiter='\\t').head(frames)\n","    psi_df = pd.read_csv(psi_path, header=None,\n","                         index_col='frame', names=['frame', 'psi'],\n","                         delimiter='\\t').head(frames)\n","\n","    phi_df = (((phi_df + 180) + phi_offset) % 360) - 180\n","    psi_df = (((psi_df + 180) + psi_offset) % 360) - 180\n","\n","    both_angles = pd.concat([phi_df['phi'], psi_df['psi']], axis=1, keys=['phi', 'psi']) * -1\n","\n","    return pd.DataFrame(both_angles)\n","\n","\n","def read_xvg(fname):\n","    \"\"\"Read columns of data from file fname\n","\n","    Returns numpy array of data\n","    \"\"\"\n","    skip = 0\n","    with open(fname, 'r') as f:\n","        for i, line in enumerate(f):\n","            if not line.startswith(('#', '@')):\n","                skip = i\n","                break\n","\n","    return np.genfromtxt(fname, skip_header=skip, usecols=(0, 1))\n","\n","\n","def apply_offset(df, phi_offset=60, psi_offset=-90, phi_mult=1, psi_mult=1):\n","    phi = df[0]\n","    psi = df[1]\n","\n","    phi = (((phi + 180) + phi_offset) % 360) - 180\n","    psi = (((psi + 180) + psi_offset) % 360) - 180\n","\n","    phi *= phi_mult\n","    psi *= psi_mult\n","\n","    return pd.DataFrame(pd.concat([phi, psi], axis=1))\n","\n","import shlex\n","import subprocess\n","import datetime\n","import os\n","import pickle\n","import time\n","from sympy.geometry import *\n","\n","import numpy as np\n","from scipy.spatial import cKDTree\n","from sklearn.cluster import MeanShift, estimate_bandwidth\n","from tqdm import tqdm\n","\n","\n","def clustering(df):\n","    # MeanShift clustering\n","    # The following bandwidth can be automatically detected using\n","    bandwidth = estimate_bandwidth(df.as_matrix(), quantile=0.2, n_samples=500)\n","    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True).fit(df.as_matrix())\n","\n","    return ms.cluster_centers_\n","\n","\n","def sample_boundaries(df, ridges, dist=15, samples=10):\n","    # now sample frames and check if those points are near the voronoi ridges\n","    delta_dist = dist  # in degree\n","    frames = {}\n","    times = []\n","    with tqdm(total=samples, desc=\"sampling frames\") as pbar:\n","        # sample transition 'positions'\n","        while len(frames) < samples:\n","            start = time.time()  # measure the time spend searching\n","            # choose random frame number\n","            rnd = np.random.randint(0, df.shape[0] - 1)\n","            frame = df.iloc[rnd]\n","            sample_point = Point(frame[0], frame[1])\n","            # check if the angles are in the defined range of the ridges\n","            for seg in ridges:\n","                rnd_offset = np.random.randint(-0.2 * delta_dist, 0.2 * delta_dist)\n","                ridge = Segment(seg[0], seg[1])\n","                if ridge.distance(sample_point) <= delta_dist + rnd_offset:\n","                    frames[rnd] = frame  # apped frame to our list\n","                    times.append(time.time() - start)  # save the time spend\n","                    pbar.update(1)\n","                    break\n","\n","    with open(\"../data/\" + str(samples) + \"_transition_states_\" + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"), 'wb') as outfile:\n","        pickle.dump(frames, outfile, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    return frames\n","\n","\n","def transition_matrix(df, ms_centers, lag_time=1):\n","    if lag_time == 0:\n","        print(\"lag_time is 0!\")\n","        return\n","\n","    tree = cKDTree(ms_centers)\n","    points = np.c_[df[0], df[1]]  # fancy zipping\n","    queries = tree.query(points, n_jobs=2)[1]\n","    trans_mat = np.zeros(shape=(len(ms_centers), len(ms_centers)))\n","    for idx in range(df.shape[0] - lag_time):\n","        old_state = queries[idx]\n","        new_state = queries[idx + lag_time]\n","        trans_mat[old_state, new_state] += 1\n","\n","    # count occurences\n","    occurences = np.zeros(shape=(len(ms_centers)))\n","    for label in queries:\n","        if label == -1:\n","            continue\n","        occurences[label] += 1\n","\n","    # normalization\n","    # T(A,B)=T(A,B)/N(B)\n","    for row in range(0, len(ms_centers)):\n","        for col in range(0, len(ms_centers)):\n","            t_a_b = trans_mat[row, col]\n","            t_b = occurences[col]\n","            trans_mat[row, col] = t_a_b / t_b\n","\n","    time_spent = occurences / occurences.sum()\n","\n","    return np.array(trans_mat).T, time_spent\n","\n","\n","def create_voronoi_ridges(vor):\n","    line_segments = []\n","    for simplex in vor.ridge_vertices:\n","        simplex = np.asarray(simplex)\n","        if np.all(simplex >= 0):\n","            line_segments.append([(x, y) for x, y in vor.vertices[simplex]])\n","\n","    ptp_bound = vor.points.ptp(axis=0)\n","\n","    center = vor.points.mean(axis=0)\n","    for pointidx, simplex in zip(vor.ridge_points, vor.ridge_vertices):\n","        simplex = np.asarray(simplex)\n","        if np.any(simplex < 0):\n","            i = simplex[simplex >= 0][0]  # finite end Voronoi vertex\n","\n","            t = vor.points[pointidx[1]] - vor.points[pointidx[0]]  # tangent\n","            t /= np.linalg.norm(t)\n","            n = np.array([-t[1], t[0]])  # normal\n","\n","            midpoint = vor.points[pointidx].mean(axis=0)\n","            direction = np.sign(np.dot(midpoint - center, n)) * n\n","            far_point = vor.vertices[i] + direction * ptp_bound.max()\n","\n","            line_segments.append([(vor.vertices[i, 0], vor.vertices[i, 1]),\n","                                  (far_point[0], far_point[1])])\n","\n","    return line_segments\n","\n","\n","def run_micro_simulations(frames, n=10, debug=False):\n","    sims = {}\n","    pbar = tqdm(total=len(frames)*n, desc=\"Simulation microstate transitions\")\n","    for idx in frames:\n","        runs = []\n","        for run in range(n):\n","            # copy topol file to simulations folder\n","            cmd = 'cp ../data/md_long.top ../simulation/short/topol.top'\n","            proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","            (out, err) = proc.communicate()\n","            if proc.returncode:\n","                raise Exception(err)\n","\n","            # copy gro file to simulations folder\n","            gro = '../data/frames/' + 'f' + str(idx) + '.gro'\n","            cmd = 'cp ' + gro + ' ../simulation/short/md.gro'\n","            proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","            (out, err) = proc.communicate()\n","            if proc.returncode:\n","                raise Exception(err)\n","\n","            # run the simulation\n","            cmd = 'bash --login ../simulation/short/short_mpi.sh'\n","            proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n","            (out, err) = proc.communicate()\n","            if proc.returncode:\n","                raise Exception(err)\n","\n","            # clean up afterwards\n","            if not debug:\n","                cmd = 'bash --login ../simulation/short/cleanup.sh'\n","                proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n","                (out, err) = proc.communicate()\n","                if proc.returncode:\n","                    raise Exception(err)\n","\n","            # copy rama file to data folder\n","            rama = '../data/xvg/' + 'f' + str(idx) + '.rama'\n","            cmd = 'cp ../simulation/short/rama.xvg ' + rama\n","            proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","            (out, err) = proc.communicate()\n","            if proc.returncode:\n","                raise Exception(err)\n","\n","            # read in the xvg and save the data\n","            runs.append(read_xvg(rama))\n","            pbar.update(1)\n","\n","        # create big array with all the data\n","        sims[idx] = runs\n","\n","    pbar.close()\n","\n","    with open('../data/' + str(len(frames)) + '_micro_sims_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"), 'wb') as outfile:\n","        pickle.dump(sims, outfile)\n","\n","    return sims\n","\n","\n","def run_macro_simulation(debug=False):\n","    # run the simulation\n","    cmd = 'bash --login simulation/long/task_mpi.sh'\n","    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n","    print(\"STDOUT:\", proc.stdout)\n","    print(\"STDERR:\", proc.stderr)\n","    print('task_mpi.sh done')\n","    (out, err) = proc.communicate()\n","    if proc.returncode:\n","       raise Exception(err)\n","    print('new command')\n","    # copy gro file of the simulation\n","    import os\n","\n","    # Get the current working directory\n","    current_directory = os.getcwd()\n","\n","    # Print the current working directory\n","    print(\"Current Working Directory:\", current_directory)\n","    cmd = 'cp simulation/long/md.gro data/md_long.gro'\n","    proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","    (out, err) = proc.communicate()\n","    if proc.returncode:\n","        raise Exception(err)\n","\n","    # copy topol file of the simulation\n","    cmd = 'cp simulation/long/topol.top data/md_long.top'\n","    proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","    (out, err) = proc.communicate()\n","    if proc.returncode:\n","        raise Exception(err)\n","\n","    # copy xtc trajectory file of the simulation\n","    cmd = 'cp simulation/long/md_corr.xtc data/md_long_corr.xtc'\n","    proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","    (out, err) = proc.communicate()\n","    if proc.returncode:\n","        raise Exception(err)\n","\n","    # save rama file to data folder\n","    cmd = 'cp simulation/long/rama.xvg data/md_long_nojump_rama.xvg'\n","    proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","    (out, err) = proc.communicate()\n","    if proc.returncode:\n","        raise Exception(err)\n","\n","    # clean up afterwards\n","    if not debug:\n","        cmd = 'bash --login simulation/long/cleanup.sh'\n","        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n","        (out, err) = proc.communicate()\n","        if proc.returncode:\n","            raise Exception(err)\n","\n","\n","\n","if __name__ == '__main__':\n","\n","    DEBUG = True\n","    samples = 20\n","\n","    # first, run a long simulation\n","    run_macro_simulation(debug=DEBUG)\n","\n","    df = pd.DataFrame(read_xvg('data/md_long_nojump_rama.xvg'))\n","    df = apply_offset(df)\n","\n","    if df.shape[0] < 1000:\n","        print(\"Not enough steps saved for analysis.\")\n","        print(\"Please configure .mdp for GROMACS simulation.\")\n","        exit(1)\n","\n","    # draw point density\n","    create_ramachandran_plot(df, \"\")\n","    print(\"Saving figure 'Ramachandran-Plot'\")\n","    plt.savefig('plots/Ramachandran-Plot', dpi=300)\n","    plt.clf()\n","\n","    ms_centers = clustering(df)\n","    vor = Voronoi(ms_centers)\n","\n","    # save cluster centers to disk\n","    with open('data/mean_shift_clusters', 'wb') as outfile:\n","        pickle.dump(ms_centers, outfile, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    # draw point density\n","    create_ramachandran_plot(df, \"\")\n","    # draw cluster centers\n","    plt.scatter(ms_centers.T[0], ms_centers.T[1], linewidths=6, color='black')\n","    print(\"Saving figure 'Ramachandran-Meanshift-Plot'\")\n","    plt.savefig('plots/Ramachandran-Meanshift-Plot', dpi=300)\n","    plt.clf()\n","\n","    create_ramachandran_plot(df, \"\")\n","    # draw cluster centers\n","    plt.scatter(ms_centers.T[0], ms_centers.T[1], linewidths=6, color='black')\n","\n","    ridge_lines = create_voronoi_ridges(vor)\n","\n","    # draw voronoi border\n","    plot_voronoi_ridges(ridge_lines)\n","    print(\"Saving figure 'Ramachandran-Voronoi-Plot'\")\n","    plt.savefig('plots/Ramachandran-Voronoi-Plot', dpi=300)\n","    plt.clf()\n","\n","    # load sampled points from disk or sample new points\n","    sample_files = glob.glob(\"data/\" + str(samples) + \"_transition_states_*\")\n","    if len(sample_files):\n","        with open(sample_files[0], 'rb') as outfile:\n","            sampled_frames = pickle.load(outfile)\n","    else:\n","        # choose only interesting ridges to sample from\n","        # sampled_frames = sample_boundaries(df, ridge_lines[3:6:1], dist=15, samples=samples)\n","        # sample from all borders\n","        sampled_frames = sample_boundaries(df, ridge_lines, dist=15, samples=samples)\n","\n","    # draw point density\n","    create_ramachandran_plot(df, \"\")\n","    # draw voronoi border\n","    plot_voronoi_ridges(ridge_lines)\n","    # draw samples\n","    plot_sampled_frames(sampled_frames)\n","\n","    print(\"Saving figure 'Ramachandran-Transitions-Plot'\")\n","    plt.savefig('plots/Ramachandran-Transitions-Plot', dpi=300)\n","    plt.clf()\n","\n","    plot_voronoi_ridges(ridge_lines)\n","    plot_sampled_frames(sampled_frames, linewidth=1)\n","    plot_frame_transitions(df, sampled_frames, \"\")\n","\n","    print(\"Saving figure 'Ramachandran-Transitions-Paths-Plot'\")\n","    plt.savefig('plots/Ramachandran-Transitions-Paths-Plot', dpi=300)\n","    plt.clf()\n","\n","    paths_files = glob.glob(\"data/\" + str(samples) + \"_micro_sims_*\")\n","    if len(paths_files):\n","        with open(paths_files[0], 'rb') as outfile:\n","            f_all = pickle.load(outfile)\n","    else:\n","        # run small simulations\n","        frame_keys = sampled_frames.keys()\n","        # Load simulation results\n","        u = MDAnalysis.Universe('data/md_long.gro', 'data/md_long_corr.xtc')\n","\n","        # save frame ids as pdb files\n","        save_frames_as_pdb(sampled_frames, u)\n","        # run small simulations and save convert to numpy\n","        f_all = run_micro_simulations(frame_keys, n=20, debug=DEBUG)\n","\n","    # plot interesting voronoi region\n","    plot_voronoi_ridges(ridge_lines)\n","\n","    # plot all micro transition paths\n","    traj = samples\n","    keys = list(f_all.keys())\n","    random.shuffle(keys)\n","    for idx in tqdm(keys[:traj], desc=\"Plotting micro transition paths\"):\n","        c = np.random.rand(3,)\n","        for t in f_all[idx]:\n","            npt = pd.DataFrame(np.array(t))\n","            npt = apply_offset(npt)\n","            # plot big transition\n","            prev = df.iloc[idx]\n","            curr = df.iloc[idx + 1]\n","            plt.plot([prev[0], curr[0]], [prev[1], curr[1]], color='black', linewidth=2)\n","            plt.plot([prev[0], curr[0]], [prev[1], curr[1]], color=c, linewidth=1)\n","            # plot micro transition\n","            plt.scatter(npt[0][0], npt[1][0], color='black', linewidth=2)\n","            plt.scatter(npt[0][0], npt[1][0], color=c, linewidth=1)\n","            plt.plot(npt[0], npt[1], color=c, linewidth=1)\n","            # plot difference\n","            plt.plot([npt[0][npt.shape[0]-1], curr[0]], [npt[1][npt.shape[0]-1], curr[1]], linestyle='--', color=c)\n","\n","    # compute transition matrices and save them\n","    t_mats = {}\n","    for i in tqdm(range(1, 4), desc=\"Computing transition matrices\"):\n","        trans_mat, time_spent = transition_matrix(df, ms_centers, lag_time=i)\n","        t_mats[i] = {'transition': trans_mat, 'time': time_spent}\n","\n","    # save transition matrices to disk\n","    with open('data/transition_matrices', 'wb') as outfile:\n","        pickle.dump(t_mats, outfile, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    print(\"Saving figure 'Micro-Transitions-Paths-Plot'\")\n","    plt.savefig('plots/Micro-Transitions-Paths-Plot', dpi=300)\n","    plt.clf()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":429},"id":"oRGsTu5WIW4k","executionInfo":{"status":"error","timestamp":1702940758167,"user_tz":-60,"elapsed":259,"user":{"displayName":"Zeno Kujawa","userId":"07762581709440442721"}},"outputId":"c7bc7977-0f91-4fdb-ab91-9cebaddb71f7"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["STDOUT: <_io.BufferedReader name=51>\n","STDERR: <_io.BufferedReader name=53>\n","task_mpi.sh done\n"]},{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-78770e036cc3>\u001b[0m in \u001b[0;36m<cell line: 413>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;31m# first, run a long simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m     \u001b[0mrun_macro_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_xvg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/md_long_nojump_rama.xvg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-78770e036cc3>\u001b[0m in \u001b[0;36mrun_macro_simulation\u001b[0;34m(debug)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m        \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new command'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;31m# copy gro file of the simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: b'bash: simulation/long/task_mpi.sh: No such file or directory\\n'"]}]},{"cell_type":"code","source":["!pip install MDAnalysis"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QnaWOxAELMQO","executionInfo":{"status":"ok","timestamp":1702940711323,"user_tz":-60,"elapsed":11023,"user":{"displayName":"Zeno Kujawa","userId":"07762581709440442721"}},"outputId":"0b34ba9a-5016-462f-f308-838a1ece4f17"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting MDAnalysis\n","  Downloading MDAnalysis-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from MDAnalysis) (1.23.5)\n","Collecting biopython>=1.80 (from MDAnalysis)\n","  Downloading biopython-1.81-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from MDAnalysis) (3.2.1)\n","Collecting GridDataFormats>=0.4.0 (from MDAnalysis)\n","  Downloading GridDataFormats-1.0.2-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mmtf-python>=1.0.0 (from MDAnalysis)\n","  Downloading mmtf_python-1.1.3-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.10/dist-packages (from MDAnalysis) (1.3.2)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from MDAnalysis) (1.11.4)\n","Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from MDAnalysis) (3.7.1)\n","Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.10/dist-packages (from MDAnalysis) (4.66.1)\n","Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from MDAnalysis) (3.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from MDAnalysis) (23.2)\n","Collecting fasteners (from MDAnalysis)\n","  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n","Collecting mrcfile (from GridDataFormats>=0.4.0->MDAnalysis)\n","  Downloading mrcfile-1.4.3-py2.py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->MDAnalysis) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->MDAnalysis) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->MDAnalysis) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->MDAnalysis) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->MDAnalysis) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->MDAnalysis) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->MDAnalysis) (2.8.2)\n","Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from mmtf-python>=1.0.0->MDAnalysis) (1.0.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.5.1->MDAnalysis) (1.16.0)\n","Installing collected packages: mrcfile, mmtf-python, fasteners, biopython, GridDataFormats, MDAnalysis\n","Successfully installed GridDataFormats-1.0.2 MDAnalysis-2.6.1 biopython-1.81 fasteners-0.19 mmtf-python-1.1.3 mrcfile-1.4.3\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yJk8Clj8LOy_"},"execution_count":null,"outputs":[]}]}